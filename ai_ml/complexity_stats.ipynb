{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from imageio import imread\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import marginal\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_grayscale_pngs(path, width=20, height=13):\n",
    "    path = Path(path)\n",
    "    if path is None:\n",
    "        return None\n",
    "\n",
    "    if not path.exists():\n",
    "        raise ValueError(\"Path {} doesn't exist\".format(path))\n",
    "\n",
    "    num_files = len(list(path.glob('**/*.png'))) # Calculate amount of files in directory\n",
    "    if num_files == 0:\n",
    "        print(\"Path {} doesn't contain any images\".format(path))\n",
    "        return None\n",
    "\n",
    "    images = np.empty((num_files, 13, 20))\n",
    "\n",
    "    for i, image_path in enumerate(sorted(path.glob('**/*.png'), key=lambda f: int(f.stem))):\n",
    "        images[i] = np.array(imread(image_path))[:, :, 0] # Pixel data: It's grayscale so take only Red values from [R, G, B, A]\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal = np.concatenate((\n",
    "    read_grayscale_pngs(\"out/legal/orig\"), \n",
    "    read_grayscale_pngs(\"out/legal/mirrored\"),\n",
    "    read_grayscale_pngs(\"out/legal/rotated5.0\"),\n",
    "    read_grayscale_pngs(\"out/legal/rotated-5.0\"),\n",
    "))\n",
    "illegal = np.concatenate((\n",
    "    read_grayscale_pngs(\"out/illegal/orig\"), \n",
    "    read_grayscale_pngs(\"out/illegal/mirrored\"),\n",
    "    read_grayscale_pngs(\"out/illegal/shifted\"),\n",
    "    read_grayscale_pngs(\"out/illegal/rotated5.0\"),\n",
    "    read_grayscale_pngs(\"out/illegal/rotated-5.0\")\n",
    "))\n",
    "\n",
    "legal_test = read_grayscale_pngs(\"testing/legal\")\n",
    "illegal_test = read_grayscale_pngs(\"testing/illegal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN\n",
    "X_train = np.concatenate((legal, illegal))\n",
    "X_train = X_train / 255.0\n",
    "Y_train = np.concatenate((np.full(len(legal), 0), np.full(len(illegal), 1)))\n",
    "\n",
    "X_test = np.concatenate((legal_test, illegal_test))\n",
    "X_test = X_test / 255.0\n",
    "Y_test = np.concatenate((np.full(len(legal_test), 0), np.full(len(illegal_test), 1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relus = 100\n",
    "\n",
    "# Reccurent\n",
    "keras.backend.clear_session()\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.InputLayer((13,20), name=\"input\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(relus,  activation=\"relu\"))\n",
    "model.add(layers.Dense(1,  activation=\"sigmoid\", name=\"output\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",  metrics=[\"binary_accuracy\"])\n",
    "\n",
    "# dot_img_file = 'tmp/ANN.pdf'\n",
    "# keras.utils.plot_model(model, to_file=dot_img_file, rankdir=\"LR\")\n",
    "%time model.fit(X_train, Y_train, shuffle=True, batch_size=20, epochs=20, verbose=0, validation_split=0.1)\n",
    "%time model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filters = 14\n",
    "kernel_size = 4\n",
    "relus = 50\n",
    "dropout = 0.3\n",
    "\n",
    "\n",
    "# Convolutional\n",
    "keras.backend.clear_session()\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.InputLayer((13,20), name=\"input\"))\n",
    "model.add(layers.Reshape((13,20,1), input_shape=(13,20)))\n",
    "model.add(layers.Conv2D(conv_filters, kernel_size, input_shape=(13,20,1), activation=\"relu\"))\n",
    "model.add(layers.Dropout(dropout))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(relus,  activation=\"relu\"))\n",
    "model.add(layers.Dense(1,  activation=\"sigmoid\", name=\"output\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",  metrics=[\"binary_accuracy\"])\n",
    "\n",
    "%time model.fit(X_train, Y_train, shuffle=True, batch_size=20, epochs=20, verbose=0, validation_split=0.1)\n",
    "%time model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_cells = 50\n",
    "relu_neurons = 50\n",
    "\n",
    "# Reccurent\n",
    "keras.backend.clear_session()\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.InputLayer((13,20), name=\"input\"))\n",
    "model.add(layers.Reshape((1,260), input_shape=(13,20)))\n",
    "model.add(layers.LSTM(rnn_cells))\n",
    "model.add(layers.Dense(relu_neurons, activation=\"relu\"))\n",
    "model.add(layers.Dense(1,  activation=\"sigmoid\", name=\"output\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",  metrics=[\"binary_accuracy\"])\n",
    "\n",
    "%time model.fit(X_train, Y_train, shuffle=True, batch_size=20, epochs=20, verbose=0, validation_split=0.1)\n",
    "%time model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal = read_grayscale_pngs(\"out/legal/orig\")\n",
    "illegal = read_grayscale_pngs(\"out/illegal/orig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = []\n",
    "for i, dataset in enumerate((legal, illegal, legal_test, illegal_test)):\n",
    "    features = pd.DataFrame({\n",
    "        \"min\": np.min(dataset, axis=(1,2)),\n",
    "        \"max\": np.max(dataset, axis=(1,2)),\n",
    "        \"mean\": np.mean(dataset, axis=(1,2)),\n",
    "        \"var\": np.var(dataset, axis=(1,2)),\n",
    "        \"sum\": np.sum(dataset, axis=(1,2)),\n",
    "        \"ptp\": np.ptp(dataset, axis=(1,2)),\n",
    "        \"std\": np.std(dataset, axis=(1,2)),\n",
    "        \"trace\": np.trace(dataset, axis1=1, axis2=2),\n",
    "\n",
    "        \"mmeanx\": np.array([marginal.mean(image, dim='x', meanNN_TF=False) for image in dataset]),\n",
    "        \"mmeanxTF\": np.array([marginal.mean(image, dim='x', meanNN_TF=True) for image in dataset]),\n",
    "\n",
    "        \"msdx\": np.array([marginal.std(image, dim='x', meanNN_TF=False) for image in dataset]),\n",
    "        \"msdxTF\": np.array([marginal.std(image, dim='x', meanNN_TF=True) for image in dataset]),\n",
    "\n",
    "        \"mmeany\": np.array([marginal.mean(image, dim='y', meanNN_TF=False) for image in dataset]),\n",
    "        \"mmeanyTF\": np.array([marginal.mean(image, dim='y', meanNN_TF=True) for image in dataset]),\n",
    "\n",
    "        \"msdy\": np.array([marginal.std(image, dim='y', meanNN_TF=False) for image in dataset]),\n",
    "        \"msdyTF\": np.array([marginal.std(image, dim='y', meanNN_TF=True) for image in dataset]),\n",
    "\n",
    "        \"target\": 0 if i % 2 == 0 else 1\n",
    "    })\n",
    "    features_list.append(features)\n",
    "\n",
    "legal_features, illegal_features, legal_test_features, illegal_test_features = tuple(features_list)\n",
    "\n",
    "chosen_features = []\n",
    "\n",
    "features = pd.concat((illegal_features, legal_features))\n",
    "X_shallow_train = features.drop('target', axis=1) if len(chosen_features) == 0 else features[chosen_features]\n",
    "Y_shallow_train = features['target']\n",
    "\n",
    "features = pd.concat((illegal_test_features, legal_test_features))\n",
    "X_shallow_test = features.drop('target', axis=1) if len(chosen_features) == 0 else features[chosen_features]\n",
    "Y_shallow_test = features['target']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "%time model.fit(X_shallow_train, Y_shallow_train)\n",
    "\n",
    "%time model.predict(X_shallow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "%time model.fit(X_shallow_train, Y_shallow_train)\n",
    "\n",
    "%time model.predict(X_shallow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()\n",
    "%time model.fit(X_shallow_train, Y_shallow_train)\n",
    "\n",
    "%time model.predict(X_shallow_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "228c518008440bb9804c44fb8714a0a32d47965f19bc294a1b65b35c54767715"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}