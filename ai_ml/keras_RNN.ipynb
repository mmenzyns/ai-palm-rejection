{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "4cb371dfbd64b115996b53cd3120a45dcd422e0f4baaeed776959a87a3804623"
   }
  },
  "interpreter": {
   "hash": "228c518008440bb9804c44fb8714a0a32d47965f19bc294a1b65b35c54767715"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from pathlib import Path\n",
    "# from tqdm.notebook import tqdm\n",
    "from imageio import imread\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_grayscale_pngs(path, width=20, height=13):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        print(\"Path {} doesn't exist\".format(path))\n",
    "        return None\n",
    "\n",
    "    # print(len([name for name in os.listdir('{}/.'.format(path)) if os.path.isfile(name)]))\n",
    "    num_files = len(list(path.glob('**/*.png'))) # Calculate amount of files in directory\n",
    "    # num_files = len([f for f in path.iterdir() if path.joinpath(f).is_file()]) # Calculate amount of files in directory\n",
    "\n",
    "    images = np.empty((num_files, 13, 20))\n",
    "\n",
    "    for i, image_path in enumerate(sorted(path.glob('**/*.png'), key=lambda f: int(f.stem))):\n",
    "        images[i] = np.array(imread(image_path))[:, :, 0] # Pixel data: It's grayscale so take only Red values from [R, G, B, A]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal = read_grayscale_pngs(\"out/legal/orig\")\n",
    "illegal = read_grayscale_pngs(\"out/illegal/orig\")  \n",
    "\n",
    "mirrored_legal = read_grayscale_pngs(\"out/legal/mirrored\")\n",
    "mirrored_illegal = read_grayscale_pngs(\"out/illegal/mirrored\")  \n",
    "\n",
    "legal_test = read_grayscale_pngs(\"testing/legal\")\n",
    "illegal_test = read_grayscale_pngs(\"testing/illegal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split# Spliiting data into test and train sets\n",
    "\n",
    "\n",
    "X_train = np.concatenate((legal, illegal))\n",
    "X_train = X_train / 255.0\n",
    "Y_train = np.concatenate((np.full(len(legal), 0), np.full(len(illegal), 1)))\n",
    "\n",
    "# X_mirror = np.concatenate((mirrored_legal, mirrored_illegal))\n",
    "# X_mirror = X_mirror / 255.0\n",
    "# Y_mirror = np.concatenate((np.full(len(mirrored_legal), 0), np.full(len(mirrored_illegal), 1))\n",
    "\n",
    "\n",
    "X_test = np.concatenate((legal_test, illegal_test))\n",
    "X_test = X_test / 255.0\n",
    "Y_test = np.concatenate((np.full(len(legal_test), 0), np.full(len(illegal_test), 1)))\n",
    "\n",
    "# X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.10, random_state=42)# fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "# train_dataset = train_dataset.shuffle(buffer_size=len(X_train), reshuffle_each_iteration=True, seed=133742).batch(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3348/3348 [==============================] - 5s 1ms/step - loss: 0.1066 - accuracy: 0.9731 - val_loss: 0.0687 - val_accuracy: 0.9892\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1.3302180767059326, 0.7325581312179565)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Convolutional\n",
    "keras.backend.clear_session()\n",
    "modelr = keras.Sequential()\n",
    "\n",
    "modelr.add(layers.Reshape((1,260), input_shape=(13,20)))\n",
    "# modelr.add(layers.Flatten())\n",
    "modelr.add(layers.LSTM(20))\n",
    "modelr.add(layers.Dense(4, activation=\"relu\"))\n",
    "modelr.add(layers.Dense(1,  activation=\"sigmoid\"))\n",
    "\n",
    "modelr.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "modelr.fit(X_train, Y_train, shuffle=False, batch_size=1, epochs=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "loss, accuracy = modelr.evaluate(X_test, Y_test, verbose=0)\n",
    "    \n",
    "print(loss, accuracy*100)"
   ]
  }
 ]
}