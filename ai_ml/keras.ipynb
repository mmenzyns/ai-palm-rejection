{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "4cb371dfbd64b115996b53cd3120a45dcd422e0f4baaeed776959a87a3804623"
   }
  },
  "interpreter": {
   "hash": "228c518008440bb9804c44fb8714a0a32d47965f19bc294a1b65b35c54767715"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from pathlib import Path\n",
    "# from tqdm.notebook import tqdm\n",
    "from imageio import imread\n",
    "\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_grayscale_pngs(path, width=20, height=13):\n",
    "    path = Path(path)\n",
    "    if not path.exists():\n",
    "        print(\"Path doesn't exist\")\n",
    "        return None\n",
    "\n",
    "    # print(len([name for name in os.listdir('{}/.'.format(path)) if os.path.isfile(name)]))\n",
    "    num_files = len(list(path.glob('**/*.png'))) # Calculate amount of files in directory\n",
    "    # num_files = len([f for f in path.iterdir() if path.joinpath(f).is_file()]) # Calculate amount of files in directory\n",
    "\n",
    "    images = np.empty((num_files, 13, 20))\n",
    "\n",
    "    for i, image_path in enumerate(sorted(path.glob('**/*.png'), key=lambda f: int(f.stem))):\n",
    "        images[i] = np.array(imread(image_path))[:, :, 0] # Pixel data: It's grayscale so take only Red values from [R, G, B, A]\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "legal = read_grayscale_pngs(\"../data_processing/out/legal/orig\")\n",
    "illegal = read_grayscale_pngs(\"../data_processing/out/illegal/orig\")  \n",
    "\n",
    "legal_test = read_grayscale_pngs(\"testing/legal\")\n",
    "illegal_test = read_grayscale_pngs(\"testing/illegal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split# Spliiting data into test and train sets\n",
    "\n",
    "\n",
    "X_train = np.concatenate((legal, illegal))\n",
    "Y_train = np.concatenate((np.full(len(legal), 0), np.full(len(illegal), 1)))\n",
    "\n",
    "\n",
    "X_test = np.concatenate((legal_test, illegal_test))\n",
    "Y_test = np.concatenate((np.full(len(legal_test), 0), np.full(len(illegal_test), 1)))\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.10, random_state=42)# fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(X_train), reshuffle_each_iteration=False, seed=133742).batch(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/16\n",
      "335/335 [==============================] - 15s 40ms/step - loss: 0.6824 - accuracy: 0.6153 - val_loss: 0.6430 - val_accuracy: 0.7339\n",
      "Epoch 2/16\n",
      "335/335 [==============================] - 16s 47ms/step - loss: 0.4567 - accuracy: 0.8444 - val_loss: 0.2958 - val_accuracy: 0.8763\n",
      "Epoch 3/16\n",
      "335/335 [==============================] - 18s 55ms/step - loss: 0.2858 - accuracy: 0.8877 - val_loss: 0.2437 - val_accuracy: 0.9113\n",
      "Epoch 4/16\n",
      "335/335 [==============================] - 20s 60ms/step - loss: 0.2068 - accuracy: 0.9289 - val_loss: 0.2076 - val_accuracy: 0.9301\n",
      "Epoch 5/16\n",
      "335/335 [==============================] - 19s 58ms/step - loss: 0.1664 - accuracy: 0.9456 - val_loss: 0.1784 - val_accuracy: 0.9435\n",
      "Epoch 6/16\n",
      "335/335 [==============================] - 19s 56ms/step - loss: 0.1172 - accuracy: 0.9665 - val_loss: 0.1081 - val_accuracy: 0.9704\n",
      "Epoch 7/16\n",
      "335/335 [==============================] - 19s 56ms/step - loss: 0.1019 - accuracy: 0.9692 - val_loss: 0.0985 - val_accuracy: 0.9785\n",
      "Epoch 8/16\n",
      "335/335 [==============================] - 19s 56ms/step - loss: 0.0987 - accuracy: 0.9746 - val_loss: 0.0907 - val_accuracy: 0.9785\n",
      "Epoch 9/16\n",
      "335/335 [==============================] - 19s 55ms/step - loss: 0.0854 - accuracy: 0.9764 - val_loss: 0.0894 - val_accuracy: 0.9758\n",
      "Epoch 10/16\n",
      "335/335 [==============================] - 18s 55ms/step - loss: 0.0702 - accuracy: 0.9800 - val_loss: 0.0798 - val_accuracy: 0.9758\n",
      "Epoch 11/16\n",
      "335/335 [==============================] - 19s 55ms/step - loss: 0.0789 - accuracy: 0.9770 - val_loss: 0.1501 - val_accuracy: 0.9597\n",
      "Epoch 12/16\n",
      "335/335 [==============================] - 19s 58ms/step - loss: 0.0779 - accuracy: 0.9722 - val_loss: 0.0733 - val_accuracy: 0.9839\n",
      "Epoch 13/16\n",
      "335/335 [==============================] - 18s 55ms/step - loss: 0.0490 - accuracy: 0.9881 - val_loss: 0.0701 - val_accuracy: 0.9839\n",
      "Epoch 14/16\n",
      "335/335 [==============================] - 19s 56ms/step - loss: 0.0420 - accuracy: 0.9898 - val_loss: 0.0663 - val_accuracy: 0.9866\n",
      "Epoch 15/16\n",
      "335/335 [==============================] - 19s 57ms/step - loss: 0.0353 - accuracy: 0.9907 - val_loss: 0.0559 - val_accuracy: 0.9866\n",
      "Epoch 16/16\n",
      "335/335 [==============================] - 19s 56ms/step - loss: 0.0405 - accuracy: 0.9866 - val_loss: 0.0693 - val_accuracy: 0.9812\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.6295722723007202, 0.7674418687820435)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "# Convolutional\n",
    "keras.backend.clear_session()\n",
    "modelr = keras.Sequential()\n",
    "\n",
    "modelr.add(layers.Reshape((260,1), input_shape=(13,20)))\n",
    "modelr.add(layers.LSTM(20))\n",
    "modelr.add(layers.Dense(4, activation=\"relu\"))\n",
    "modelr.add(layers.Dense(1,  activation=\"sigmoid\"))\n",
    "\n",
    "modelr.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "modelr.fit(train_dataset, shuffle=False, epochs=16, validation_data=(X_val, Y_val))\n",
    "\n",
    "loss, accuracy = modelr.evaluate(X_test, Y_test, verbose=0)\n",
    "    \n",
    "loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 13, 20, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 13, 20, 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional\n",
    "keras.backend.clear_session()\n",
    "modelc = keras.Sequential()\n",
    "\n",
    "modelc.add(layers.Reshape((13,20,1), input_shape=(13,20)))\n",
    "modelc.add(layers.Conv2D(1, 2, input_shape=(13,20,1), activation=\"relu\"))\n",
    "modelc.add(layers.Flatten())\n",
    "modelc.add(layers.Dense(10, activation=\"relu\"))\n",
    "modelc.add(layers.Dense(1,  activation=\"sigmoid\"))\n",
    "# model.summary()\n",
    "modelc.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "modelc.save_weights(\"modelc.h5\") # loaded_model.load_weights(\"model.h5\")\n",
    "modelc.fit(train_dataset, shuffle=False, epochs=16, validation_data=(X_val, Y_val))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    \n",
    "loss, accuracy"
   ]
  }
 ]
}